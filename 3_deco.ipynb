{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b01eff6",
   "metadata": {},
   "source": [
    "### üß† Decoder-Only Architecture Example ‚Äî Next Word Prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f359900",
   "metadata": {},
   "source": [
    "- Let‚Äôs say we want to predict the next word in a sentence:\n",
    "\n",
    "- ‚ÄúI love‚Äù"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8331f40",
   "metadata": {},
   "source": [
    "### Tokenization & Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc9400e",
   "metadata": {},
   "source": [
    "- Input tokens (so far):\n",
    "```raw\n",
    "[\"I\", \"love\"]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7bec183",
   "metadata": {},
   "source": [
    "- Suppose the embeddings are:\n",
    "```raw\n",
    "X = [\n",
    "  [0.1, 0.3],  # \"I\"\n",
    "  [0.4, 0.5]   # \"love\"\n",
    "]\n",
    "\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e52697",
   "metadata": {},
   "source": [
    "- Add positional encodings (to give order info):\n",
    "```raw\n",
    "X_pos = [\n",
    "  [0.15, 0.35],  # \"I\" + pos1\n",
    "  [0.45, 0.55]   # \"love\" + pos2\n",
    "]\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b727d5dc",
   "metadata": {},
   "source": [
    "### Step 2: Masked Self-Attention\n",
    "- Unlike encoder‚Äìdecoder, there‚Äôs no encoder here ‚Äî\n",
    "only a stack of decoder blocks that look at past tokens only (causal masking)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bea4c99",
   "metadata": {},
   "source": [
    "- We compute attention within the sequence `\"I love\"`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b814f1a8",
   "metadata": {},
   "source": [
    "| Token  | Can Attend To |\n",
    "| :----- | :------------ |\n",
    "| \"I\"    | \"I\"           |\n",
    "| \"love\" | \"I\", \"love\"   |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6e5a4e",
   "metadata": {},
   "source": [
    "- Let‚Äôs compute attention for the second token (\"love\") as an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "507c7eab",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8c43d8",
   "metadata": {},
   "source": [
    "- a. Compute Queries, Keys, Values\n",
    "\n",
    "Each token embedding is projected into query, key, and value vectors:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0def93db",
   "metadata": {},
   "source": [
    "```raw\n",
    "\"I\":    Q1=[0.1,0.2], K1=[0.2,0.1], V1=[0.3,0.4]\n",
    "\"love\": Q2=[0.3,0.3], K2=[0.1,0.3], V2=[0.5,0.6]\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d4e74d",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
